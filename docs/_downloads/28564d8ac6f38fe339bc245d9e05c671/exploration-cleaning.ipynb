{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Stroke Prediction - Data Exploration and Cleaning\n\nNow let's dive in a bit deeper and have a look at some code snippets!\n\nThe source code for this tutorial is located in\n``examples/1-binary-stroke-prediction`` and consists of a few numbered scripts as\nwell as the ``helpers`` module which contains a function for loading and\ncleaning the dataset. We will begin by looking at the ``helpers`` module.\n\n\n\n## Textual Data Inspection\n\n\nFirst, we load the data from the ``*.csv`` file using :func:`pandas.read_csv`\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ndata = pd.read_csv('healthcare-dataset-stroke-data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "which returns a :class:`pandas.DataFrame`. Objects of this type come with a\nfew methods for inspecting them in textual form already.\n\nThe :meth:`pandas.DataFrame.dtypes` method yields\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(data.dtypes)  # datatype of each column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "with ``object`` indicating string category labels. This can be seen explicitly\nwith the :meth:`pandas.DataFrame.head` command, which outputs\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(data.head)    # table with first few lines of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, some categorical columns contain string labels, e.g.\n``Yes``/``No`` in the column ``ever_married``, while others are labelled with\nintegers, e.g. ``0``/``1`` in the column ``hypertension``, leading to the\nindicated datatypes.\n\nThe :meth:`pandas.DataFrame.count` method counts the valid datapoints in each\ncolumn, ignoring ``NaN`` values\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(data.count()) # count valid datapoints - something going on with 'bmi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the variable ``bmi`` contains 4909 entries as opposed to\n5110 for the other columns. When printing it, we can see the ``NaN`` values\nexplicitely\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(data['bmi'])  # print column - 'bmi' contains floats and 'NaN'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "corresponding to ``N/A`` entries in the original ``*.csv`` file.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning\n\nThere are different ways of handling *missing data* such as these ``NaN``\nvalues. One option is *imputation* where the missing values are replaced\nwith other plausible values, such as the mean of the other values.\nHere, we are just going to drop the corresponding datapoints entirely:\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``inplace=True`` means that the existing :class:`pandas.DataFrame` ``data``\nitself is modified and the datapoints containing missing values are removed.\nOtherwise, ``data`` would be left unaltered and a new copy would be returned\nwith the affected datapoints removed.\n\nLet's also delete the ``id`` column:\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data.drop(columns=['id'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the dataset is slimmed down to the relevant information, let's\ncontinue by bringing the variable names and the categorical string labels\ninto a consistent form that is instantly informative when later plotting\nthe data:\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# clean up variable names\nrename_dict = {'Residence_type': 'residence_type'}\ndata.rename(columns=rename_dict, inplace=True)\n\n# clean up datatypes\nreplace_dict = {\n    'ever_married': {'No': 'no', 'Yes': 'yes'},\n    'gender': {\n        'Female': 'female',\n        'Male': 'male',\n        'Other': 'other'\n    },\n    'heart_disease': {0: 'no', 1: 'yes'},\n    'hypertension': {0: 'no', 1: 'yes'},\n    'residence_type': {\n        'Urban': 'urban',\n        'Rural': 'rural'\n    },\n    'smoking_status': {\n        'Unknown': 'unknown',\n        'never smoked': 'never',\n        'formerly smoked': 'formerly'\n    },\n    'work_type': {\n        'Govt_job': 'govt',\n        'Never_worked': 'never',\n        'Private': 'private',\n        'Self-employed': 'self'\n    },\n    'stroke': {0: 'no', 1: 'yes'}\n}\ndata.replace(replace_dict, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first part just converts the variable name to lower-case, consistent with\nthe other variable names. Similar lower-case consistency is also implemented\nin the second part for the names of the different categorical classes.\nHowever, the second part also replaces the integer values ``0`` and ``1``\nwith their slightly more expressive text counterparts ``'no'`` and ``'yes'``.\nWhile such string labels are of course not adequate for feeding into a\nneural network, this is just a tad more intuitive in the plots we are about\nto create in a moment. Bringing them into a form that can be handled by the\nnetwork will be done afterwards as part of the preprocessing and input pipeline.\n\nIt is always handy to have lists with the names of the feature and target\nvariables at hand, so let's create these:\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create lists of variable names\nvars = list(data)\ntarget = 'stroke'\nfeatures = vars.copy()   # make a copy to protect the original list\nfeatures.remove(target)  # from being modified by the 'remove' statement\nprint(target)\nprint(features)\nprint(vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember to protect ``vars`` by making ``features`` a copy of it!\n\nFinally, let's check that *spellbook* correctly identifies each variable as\n*categorical* or *continuous*. This is used in the high-level plotting\nfunctions in :mod:`spellbook.plot` for automatically choosing the adequate\nvisual representation for each variable, e.g. barcharts or histograms for\n1D/univariate plots and heatmaps, multiple horizontal histograms or\nscatterplots for 2D/bivariate/correlation plots:\n\n.. margin:: from **helpers.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import spellbook as sb\nsb.plotutils.print_data_kinds(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Visualisation\n\nNow, finally, let's start plotting the dataset. In this section we'll walk\nthrough the code in ``1-plot.py``.\n\nIt begins by loading and cleaning the data using the helper function\nintroduced before:\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    import helpers\n    data, vars, target, features = helpers.load_data()\n\nIndividual univariate plots can be created with :func:`spellbook.plot.plot_1D`,\nwhich creates and returns a :class:`matplotlib.figure.Figure` object, and\n:func:`spellbook.plot.save`, which saves a figure to a file:\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    fig = sb.plot.plot_1D(data=data, x='stroke', fontsize=14.0)\n    sb.plot.save(fig, filename='stroke.png')\n\nA slightly more involved example, with both plotting and saving chained after\none another, is:\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    sb.plot.save(\n        sb.plot.plot_1D(\n            data = data,\n            x = 'avg_glucose_level',\n            xlabel = 'Average Glucose Level',\n            statsbox_args = {\n                'text_args': {'backgroundcolor': 'white'}\n            }\n        ),\n        filename='avg_glucose_level.png'\n    )\n\nThese commands create plots of the target variable ``stroke`` (Figure 12) and\none of the feature variables, ``avg_glucose_level`` (Figure 13):\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/1-binary-stroke-prediction/stroke.png\n          :height: 250px\n\n          Figure 12: barchart\n\n     - .. figure:: /images/examples/1-binary-stroke-prediction/avg_glucose_level.png\n          :height: 250px\n\n          Figure 13: histogram\n\nThe type of plot is determined automatically by :func:`spellbook.plot.plot_1D`\naccording to the kind of the variable: For categorical variables,\n:func:`spellbook.plot1D.barchart` is called, and for continuous variables,\n:func:`spellbook.plot1D.histogram`. The histogram comes with a few additional\nvisual elements indicating descriptive statistics, such as the mean, median,\nstandard deviation, quantiles, as well as a box in which the numerical\nvalues of all the statistics are given. All these elements can be switched on\nand off individually.\n\nIt is also possible to plot multiple variables arranged in a grid with\n:func:`spellbook.plot.plot_grid_1D`:\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    # plot all target and feature distributions\n    sb.plot.save(\n        sb.plot.plot_grid_1D(\n            nrows=3, ncols=4, data=data, target=target, features=features,\n            stats=False, fontsize=11.0\n        ),\n        filename='variables.png'\n    )\n\n    # plot a subset of the feature variables\n    sb.plot.save(\n        sb.plot.plot_grid_1D(\n            nrows=2, ncols=3, data=data,\n            features=['age', 'hypertension', 'heart_disease',\n                      'bmi', 'avg_glucose_level', 'smoking_status'],\n            stats=False, fontsize=11.0\n        ),\n        filename='variables-health.png'\n    )\n\nThe first command creates a grid plot of all variables, both the target variable\nas well as all of the feature variables (Figure 14). The target variable is\nshown first and highlighted in orange. The second command creates a plot of a\nsubset of the feature variables (Figure 15). The statistics boxes are\ndeactivated so as to not overcrowd the plots.\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/1-binary-stroke-prediction/variables.png\n          :height: 250px\n\n          Figure 14: grid plot of the target and all feature variables\n\n     - .. figure:: /images/examples/1-binary-stroke-prediction/variables-health.png\n          :height: 250px\n\n          Figure 15: grid plot of a subset of the feature variables\n\nAs we have already seen in the summary version on the previous page,\nthere are far fewer patients with a stroke than without, making the dataset\n*imbalanced*. We can also see that a majority of 60% of the patients\nare female and that the age distribution is slightly concentrated at medium\nages between 40 and 60 and falls off a bit towards the edges, with the notable\nexception of the first and last bin. 9% of the patients have hypertension\nand 5% of them suffer from a heart condition. About two thirds of them are\nmarried or have been married at least once. The majority, about 57%, work in\nthe private sector. The dataset is pretty balanced with regard to where\nthe patients live (urban or rural areas). The distribution of the average\nglucose level shows a secondary peak just above 200, pulling the mean slightly\nabove the median. The BMI distribution has a slight tail on the right-hand\nside, but is otherwise centered at around 30, which is the boundary between\nthe *overweight* and *moderately obese (class 1)* categories. Finally,\nabout 38% of the patients have never smoked, 17% and 15% are former and current\nsmokers, respectively, and for the remaining 30%, it is not known if they\ndo or do not smoke.\n\nThis is all good and fine, but more interesting than univariate plots are\nbivariate plots showing the correlations between different variables. So let's\ngo ahead and create some! Let's start with single plots containing just one\ncorrelation. These can be generated with :func:`spellbook.plot.plot_2D`,\nwhich automatically calls the appropriate function from\n:mod:`spellbook.plot2D`, depending on whether the variables on the x- and\ny-axes are categorical or continuous:\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    sb.plot.save( # default: no descriptive statistics\n        sb.plot.plot_2D(data=data, x='age', y=target, fontsize=14.0),\n        filename='age-corr.png'\n    )\n    sb.plot.save( # boxes with descriptive statistics included\n        sb.plot.plot_2D(\n            data=data, x='age', y=target, fontsize=11.0,\n            histogram_args = [\n                dict(show_stats=True, statsbox_args={'alignment': 'bl'}),\n                dict(\n                    show_stats = True,\n                    statsbox_args = {\n                        'y': 0.96,\n                        'text_args': {\n                            # RGBA white with 50% alpha/opacity\n                            'backgroundcolor': (1.0, 1.0, 1.0, 0.5)\n                        }\n                    }\n                )\n            ]\n        ),\n        filename='age-corr-stats.png'\n    )\n\nCorrelations between a continuous variable on the x-axis and a categorical\nvariable on the y-axis are shown as a sequence of histograms for each of the\ny-categories, plotted one above the other. These categorical histograms are\nimplemented in :func:`spellbook.plot2D.categorical_histogram`.\nThe first example (Figure 16) is the default configuration where the boxes\nindicating the descriptive statistics are suppressed. The second version\n(Figure 17) shows how to activate and configure them.\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/1-binary-stroke-prediction/age-corr.png\n          :height: 250px\n\n          Figure 16: default bivariate histogram\n\n     - .. figure:: /images/examples/1-binary-stroke-prediction/age-corr-stats.png\n          :height: 250px\n\n          Figure 17: bivariate histogram with descriptive statistics included\n\nNow let's plot the correlations of all feature variables with the target\nwith :func:`spellbook.plot.plot_grid_2D`.\nCorrelations between categorical values on both the x-axis and the y-axis are\nshown as heatmaps, see :func:`spellbook.plot2D.heatmap`. Here, we first plot\nthe correlation with absolute numbers in the heatmaps, and then normalised\nalong the columns:\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    # absolute values\n    fig = sb.plot.plot_grid_2D(nrows=2, ncols=5, data=data, xs=features, ys=target)\n    sb.plot2D.heatmap_set_annotations_fontsize(\n        ax=fig.get_axes()[7], fontsize='x-small')\n    sb.plot2D.heatmap_set_annotations_fontsize(\n        ax=fig.get_axes()[15], fontsize='small')\n    sb.plot.save(fig, 'corrs-absolute.png')\n\n    # relative values\n    fig = sb.plot.plot_grid_2D(\n        nrows=2, ncols=5, data=data, xs=features, ys=target, relative='true')\n    sb.plot2D.heatmap_set_annotations_fontsize(\n        ax=fig.get_axes()[7], fontsize='x-small')\n    sb.plot2D.heatmap_set_annotations_fontsize(\n        ax=fig.get_axes()[15], fontsize='small')\n    sb.plot.save(fig, 'corrs-relative.png')\n\nThe resulting plots are shown in Figure 18 and 19:\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/1-binary-stroke-prediction/corrs-absolute.png\n          :height: 200px\n\n          Figure 18: Correlations with absolute numbers in the heatmaps\n\n     - .. figure:: /images/examples/1-binary-stroke-prediction/corrs-relative.png\n          :height: 200px\n\n          Figure 19: Correlations with heatmaps normalised along the columns\n\nAs you see in the code snippet, we are adjusting the fontsize in the cells of\nsome of the heatmaps with the\n:func:`spellbook.plot2D.heatmap_set_annotations_fontsize` function.\nIn order to do this, we have to point it to the correct\n:class:`matplotlib.axes.Axes` object. Each grid plot has one *axes* in each\nof the grid cells. Additionally, categorical histograms have one *axes*\nobject for each category. Therefore, the grid cell showing the\n``stroke``-``work_type`` correlation (bottom left) has the index ``7`` and\n``stroke``-``smoking_status`` correlation (bottom right) the index ``15``.\n\nLooking at the correlations shown in the plots, we can see that men and women\nhave about the same stroke rate - the small difference of 0.3% is likely not\nsignificant. Strokes are more likely with increasing age and show correlations\nwith hypertension and heart conditions. Curiously enough there is a correlation\nbetween the presence of a stroke and the marriage status. But we should not\nconfuse correlation and causation here - strokes are probably not *due to*\nmarriages or divorces, at least not entirely, and this correlation is likely\na consequence of the correlation between marriage status and age and the\ncorrelation of age with the stroke rate - or rather the underlying causal\nrelation between declining health and increasing age. Regarding the type of\nwork, self-employed patients seem to have a slightly higher stroke rate than\npeople working in the private sector or government jobs. For children and\npeople who have never worked, the stroke rate is practically zero, which again\nis likely to be a consequence of their young age. Residence type and BMI\nshow no correlations with the presence of strokes while for the average\nglucose level, the secondary peak seems to be a tad more pronounced among\nstroke patients. Finally, former and current smokers seem to show a slightly\nelevated stroke rate - however, the statistical significance of these numbers\nis not large. It is also curious that the stroke rate is least among patients\nfor which the smoking habits are not known. Since no options other\nthan *smokes*, *formerly* and *never* come to mind, I would have expected\nthis category to show similar stroke rates as the others. Given that the\n*unknown* category contains as many patients as the *former* and *smokes*\ncategories combined, its lower stroke rate is indeed statistically significant\nwhich makes a statistical fluctuation unlikely.\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    sb.plot.save(sb.plot.plot_2D(data=data, x='age', y='ever_married'),\n        filename='corr-married-age.png')\n    sb.plot.save(sb.plot.plot_2D(data=data, x='age', y='work_type'),\n        filename='corr-work-age.png')\n\nThis snippet generates plots of the correlations between age and marriage\nstatus (Figure 20) as well as age and type of work (Figure 21). As mentioned\nin the last paragraph, these do show correlations and are likely the deeper\nreason for the correlations between marriage status, work type and strokes.\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/1-binary-stroke-prediction/corr-married-age.png\n          :height: 250px\n\n          Figure 20: Correlation between marriage status and age\n\n     - .. figure:: /images/examples/1-binary-stroke-prediction/corr-work-age.png\n          :height: 250px\n\n          Figure 21: Correlation between work type and age\n\nFinally, pairplots are a handy tool for showing the correlations between\nall possible combinations of variables along with the individual distributions\nof each variable. They can be created with :func:`spellbook.plot.pairplot`,\nwhich like the other functions chooses the appropriate representation\nautomatically. In *spellbook*, it is possible to\nplot both all correlations, resulting in a square plot grid, but also\nsubsets of all possible correlations, with different variables on the x- and\ny-axes, resulting in rectangular plot grids. Examples for both options are:\n\n.. margin:: from **1-plot.py**\n\n    in ``examples/1-binary-stroke-prediction/``\n\n.. code:: python\n\n    # 3x5 pairplot\n    vars = ['ever_married', 'age', 'hypertension', 'heart_disease', 'bmi', 'stroke']\n    pairplot = sb.plot.pairplot(data, xs=vars[:5], ys=vars[1:4])\n    sb.plot.save(pairplot, 'pairplot-3x5.png')\n\n    # full pairplot of all features\n    sb.plot.save(\n        sb.plot.pairplot(data, xs=features),\n        filename='pairplot-features.png', dpi=100)\n\nFor the full pairplot, the resolution was decreased to 100dpi to keep the\nfilesize at bay. The resulting plots are shown in Figures 22 and 23:\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/1-binary-stroke-prediction/pairplot-3x5.png\n          :height: 300px\n\n          Figure 22: 3x5 pairplot of a subset of the features\n\n     - .. figure:: /images/examples/1-binary-stroke-prediction/pairplot-features.png\n          :height: 300px\n\n          Figure 23: Full paiplot for all features\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}