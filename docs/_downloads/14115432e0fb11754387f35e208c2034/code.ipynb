{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Random Forests and Gradient Boosted Trees in *TensorFlow*\n\n\n.. raw:: html\n\n    <div class=\"tag-list\">\n       <div class=\"tag-cell tag-date\">June 16, 2021</div>\n       <div class=\"tag-cell tag-center\"></div>\n       <div class=\"tag-cell tag-right\">\n          <span class=\"tag-text\">tags:</span>\n          <a class=\"tag right\" href=\"../../search.html?q=tags+binary+classification\">\n             binary classification</a>\n          <a class=\"tag right\" href=\"../../search.html?q=tags+gradient+boosted+trees\">\n             gradient boosted trees</a>\n          <a class=\"tag right\" href=\"../../search.html?q=tags+decision+forest\">\n             decision forest</a>\n          <a class=\"tag right\" href=\"../../search.html?q=tags+supervised+learning\">\n             supervised learning</a>\n        </div>\n    </div>\n\n\n\n.. admonition:: In this project/tutorial, we will\n   :class: spellbook-admonition-orange\n \n   - Visualise the `Stroke Prediction Dataset\n     <https://www.kaggle.com/fedesoriano/stroke-prediction-dataset>`_\n     with a **parallel coordinate plot**\n   - Use **TensorFlow Decision Forests** (**TF-DF**) to train a\n     **random forest** and a **gradient boosted trees** model to do\n     **binary classification**\n   - **Compare the performance** of the tree models **against the neural\n     network** trained in the previous tutorial\n     :doc:`/examples/1-binary-stroke-prediction/index`\n\n\nIn *TensorFlow* version 2.5.0, support for *decision trees* and *forests*\nwas added and `announced <https://youtu.be/5qgk9QJ4rdQ>`_ during\nGoogle I/O 2021. The documentation, including guides, tutorials and the\nAPI reference can be found `here\n<https://www.tensorflow.org/decision_forests>`_.\n*TensorFlow Decision Forests* (*TF-DF*) includes the models\n\n- `tfdf.keras.RandomForestModel\n  <https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/RandomForestModel>`_\n- `tfdf.keras.GradientBoostedTreesModel\n  <https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel>`_\n\nwhich we are going to explore in this tutorial.\n\n\n## Installation\n\nAs of now, *TensorFlow Decision Forests* is not yet available on *Anaconda*\nand instead has to be installed from the `Python Package Index\n<https://pypi.org/project/tensorflow-decision-forests/>`_ via ``pip``.\nCombining package installations via *conda* and *pip* should be done with a\ncertain level of care. Following *spellbook*'s typical setup specified in\n``spellbook.yml`` and combining the normal *conda*-based *TensorFlow*\ninstallation with *TF-DF* installed via ``pip`` will most probably not work.\nInstead, we are going to create a separate *conda* environment\n``spellbook-no-tensorflow`` just for this tutorial and install both\n*TensorFlow* and *TF-DF* via ``pip`` using the provided ``requirements.txt``.\n\nSo let's roll:\n\n.. code:: bash\n\n   $ cd examples/2-tensorflow-decision-forests\n\nIf the default ``spellbook`` *conda* environment is currently active,\ndeactivate it\n\n.. code:: bash\n\n    $ conda deactivate\n\nand create the dedicated environment excluding *TensorFlow*\n\n.. code:: bash\n\n   $ conda env create --file spellbook-no-tensorflow.yml\n\nOnce this is done, activate it and use ``pip`` to install both *TensorFlow*\nand *TensorFlow Decision Forests* into the new *conda* environment\n``spellbook-no-tensorflow``\n\n.. code:: bash\n\n   $ conda activate spellbook-no-tensorflow\n   $ pip install -r requirements.txt\n\n\n\n## Parallel Coordinate Plots\n\nThis tutorial uses Kaggle's `Stroke Prediction Dataset\n<https://www.kaggle.com/fedesoriano/stroke-prediction-dataset>`_,\njust like the :doc:`/examples/1-binary-stroke-prediction/index` project before.\nSo therefore, before we try out the decision trees in *TF-DF*, let's have\na look at another possibility of visualising entire datasets in a rather\ncompact way - *parallel coordinate plots*. In *spellbook*, they are\nimplemented in :func:`spellbook.plot.parallel_coordinates` and can be used\nlike this:\n\n.. margin:: from **1-plot.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   fig = sb.plot.parallel_coordinates(data.sample(frac=1.0).iloc[:500],\n      features, target, categories)\n   sb.plot.save(fig, 'parallel-coordinates.png')\n\nWe first shuffle the datapoints using :meth:`pandas.DataFrame.sample` and\nthen take the first 500 of them in order to get a\nrepresentative subset of all patients. The resulting plot is shown in\nFigure 1.\n\n.. list-table::\n   :class: spellbook-gallery-wrap, perc90\n\n   * - .. figure:: /images/examples/2-tensorflow-decision-forests/parallel-coordinates.png\n          :align: center\n          :width: 90%\n\n          Figure 1: Parallel coordinates plot showing a subset of\n          Kaggle's Stroke Prediction Dataset\n\nWe can see the binary categorical target variable ``stroke`` on the far\nright-hand side of the plot. Patients with a stroke are shown with orange\nlines and patients without a stroke with blue lines. The features are shown\nin individual coordinate axes left of the target. There are both continuous\nvariables, such as ``age`` or ``bmi``, and categorical variables, such as\n``gender`` or ``heart_disease`` and the density of the lines indicates the\nprevalence of the target labels. Looking at the age of the patients, we can\nsee that strokes are more present at higher ages.\nFor categorical variables, the datapoints are randomly\nsmeared or shifted around the respective categories or classes. Therefore,\nthe lines are not all drawn exactly on top of each other and it is possible\nto get an impression of the composition of the datapoints in a certain category\nin terms of the target labels. For instance, we can see that the ``no``\nclasses of the variables ``hypertension`` and ``heart_disease`` contain\nsignificant fractions of patients both with and without strokes, while the\n``yes`` categories seem to be enriched in stroke patients. This seems\nplausible as it indicates positive correlations between these conditions\nand the presence of strokes. Additionally, the size of the smearing or\nshifting interval is chosen in proportion to the number of datapoints in\nthe respective categories. Therefore, it is possible to get a feeling for\nhow many patients fall into which class for each feature. For example, we\ncan see that more patients work in the private sector that for the\ngovernment.\n\n\n\n## Random Forest\n\nJust like regular *TensorFlow*, *TF-DF* implements the *Keras* API and\ntherefore, we can follow very closely what we did in\n:doc:`/examples/1-binary-stroke-prediction/index`.\nSo now let's start using *TF-DF* and begin with the random forest model:\n\n.. margin:: from **2-random-forest.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   # data loading and cleaning\n   data, vars, target, features = helpers.load_data()\n   \n   # inplace convert string category labels to numerical indices\n   categories = sb.input.encode_categories(data)\n   \n   # oversampling (including shuffling of the data)\n   data = sb.input.oversample(data, target)\n   \n   # split into training and validation data\n   n_split = 7000\n   train = tfdf.keras.pd_dataframe_to_tf_dataset(\n       data[features+[target]].iloc[:n_split], label=target)\n   val = tfdf.keras.pd_dataframe_to_tf_dataset(\n       data[features+[target]].iloc[n_split:], label=target)\n\nAfter loading the `Stroke Prediction Dataset\n<https://www.kaggle.com/fedesoriano/stroke-prediction-dataset>`_ with the\nhelper function, we apply oversampling to counteract the imbalance in the\ntarget classes between the 4.3% of the patients with a stroke and the\noverwhelming majority of 95.7% without a stroke. The dataset and the method\nof oversampling are described in detail in\n:doc:`/examples/1-binary-stroke-prediction/index`.\nFinally, we split the dataset into a training and a validation set using\n*TF-DF*'s `tfdf.keras.pd_dataframe_to_tf_dataset\n<https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/pd_dataframe_to_tf_dataset>`_.\n\nNote that we hardly did any preprocessing - in particular, decision trees do\nnot need normalised data. Likewise, it is not necessary to turn categorical\nvariables expressed by strings or integers into properly indexed\n:class:`pandas.Categorical`\\s. This is only needed here for the oversampling\nto work - but not for the decision trees.\n\nNext, we prepare a range of metrics useful for binary classification - the same\nones that are also used and described in\n:doc:`/_examples/1-binary-stroke-prediction/training-validation`.\nAfterwards, we instantiate a `tfdf.keras.RandomForestModel\n<https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/RandomForestModel>`_,\nsticking to the default values. We add the metrics using the ``compile`` method\nand train the model with ``model.fit`` on the training dataset ``train``.\nFinally, we save the model so that it can be reloaded and used again later:\n\n.. margin:: from **2-random-forest.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   # define binary metrics\n   metrics = [\n       tf.keras.metrics.BinaryCrossentropy(name='binary_crossentropy'),\n       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n       tf.keras.metrics.TruePositives(name='tp'),\n       tf.keras.metrics.TrueNegatives(name='tn'),\n       tf.keras.metrics.FalsePositives(name='fp'),\n       tf.keras.metrics.FalseNegatives(name='fn'),\n       tf.keras.metrics.Recall(name='recall'),\n       tf.keras.metrics.Precision(name='precision')\n   ]\n   \n   # prepare and train the model\n   model = tfdf.keras.RandomForestModel()\n   model.compile(metrics=metrics)\n   model.fit(train)\n   # model.summary()\n   model.save('model-{}'.format(prefix))\n   \nBy default, ``tfdf.keras.RandomForestModel`` uses 300 trees with a depth of\nup to 16 and fitting our training dataset only takes a few seconds. The\nrapid way of evaluating the model performance goes somewhat like this:\n\n.. margin:: from **2-random-forest.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   eval = model.evaluate(val, return_dict=True)\n   print('eval:', eval)\n\n``eval`` is a :class:`dict` containing the values of the metrics calculated\nfrom the validation dataset.\n\nBut let's go on and calculate and plot the confusion matrix with\n:func:`tf.math.confusion_matrix` and\n:func:`spellbook.plot.plot_confusion_matrix`. As usual, the plot is saved\nwith :func:`spellbook.plot.save`:\n\n.. margin:: from **2-random-forest.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   # separate the datasets into features and labels\n   train_features, train_labels = zip(*train.unbatch())\n   val_features, val_labels = zip(*val.unbatch())\n   \n   # obtain the predictions of the model\n   train_predictions = model.predict(train)\n   val_predictions = model.predict(val)\n   \n   # not strictly necessary: remove the superfluous inner nesting\n   train_predictions = tf.reshape(train_predictions, train_predictions.shape[0])\n   val_predictions = tf.reshape(val_predictions, val_predictions.shape[0])\n   \n   # until now the predictions are still continuous in [0, 1] and this breaks the\n   # calculation of the confusion matrix, so we need to set them to either 0 or 1\n   # according to an intermediate threshold of 0.5\n   train_predicted_labels = sb.train.get_binary_labels(\n       train_predictions, threshold=0.5)\n   val_predicted_labels = sb.train.get_binary_labels(\n       val_predictions, threshold=0.5)\n   \n   # calculate and plot the confusion matrix\n   class_names = list(categories['stroke'].values())\n   class_ids = list(categories['stroke'].keys())\n   val_confusion_matrix = tf.math.confusion_matrix(\n       val_labels, val_predicted_labels, num_classes=len(class_names))\n   sb.plot.save(\n       sb.plot.plot_confusion_matrix(\n           confusion_matrix = val_confusion_matrix,\n           class_names = class_names,\n           class_ids = class_ids),\n       filename = '{}-confusion.png'.format(prefix))\n\nJust like in\n:doc:`/_examples/1-binary-stroke-prediction/training-validation`, we can also\nplot normalised versions of the confusion matrix. The confusion matrix with\nthe absolute datapoint numbers is given in Figure 2 and a version where\neach true label/class is normalised in Figure 3:\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/2-tensorflow-decision-forests/random-forest-confusion.png\n          :height: 300px\n\n          Figure 2: Confusion matrix with absolute datapoint numbers\n\n     - .. figure:: /images/examples/2-tensorflow-decision-forests/random-forest-confusion-norm-true.png\n          :height: 300px\n\n          Figure 3: Confusion matrix normalised along each true label/class\n\nWe can see that already with the default forest configuration, the model's\nperformance is good enough to not produce any false negatives. As for the\nfalse positives, only 5.5% of the truly negative datapoints are wrongly\nclassified as positive.\n\n\n\n## Gradient Boosted Trees\n\nRandom forests consist of many trees, each trained on a randomly drawn\nsubset of the full training dataset. In contrast, a boosted decision trees\nmodel consists of many trees, where after training one tree, the weights of\nthe wrongly classified datapoints are increased before training the next tree.\nThis way, increasingly more importance is puts on datapoints that are hard\nto classify.\n\nThe only real change we have to make to use a gradient boosted trees model\nis in the instantiation:\n\n.. margin:: from **3-gradient-trees.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   model = tfdf.keras.GradientBoostedTreesModel()\n\nBy default, *TF-DF* trains up to 300 trees with a depth of up to 6.\n\nThe resulting confusion matrices are shown in Figure 4 and 5:\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/2-tensorflow-decision-forests/gradient-trees-confusion.png\n          :height: 300px\n\n          Figure 4: Confusion matrix with absolute datapoint numbers\n\n     - .. figure:: /images/examples/2-tensorflow-decision-forests/gradient-trees-confusion-norm-true.png\n          :height: 300px\n\n          Figure 5: Confusion matrix normalised along each true label/class\n\nWe can see that the performance is very similar to the random forest, with a\n*false positive rate* (:term:`FPR`) of 5.8%.\n\nBefore we go on to compare the different tree models and the final neural\nnetwork classifier trained in\n:doc:`/examples/1-binary-stroke-prediction/index`,\nlet's have a look at a model-agnostic way of determining the importance\nthat each feature plays in the performance of the classifier: the\n*permutation importance*. While one or more input features cannot simply\nbe removed, the idea behind *permutation importance* is to break the\ncorrelation of a feature with the target by randomly permuting the values\nof just that particular feature - hence the name. This way, the classifier\nis no longer able to use that feature when deriving the prediction.\nPermutation importance is implemented in *spellbook* in\n:class:`spellbook.inspect.PermutationImportance`, based on\n:func:`sklearn.inspection.permutation_importance`, and can be calculated\nand plotted as follows for any of the metrics previously defined and passed\nto the model in the ``compile`` step:\n\n.. margin:: from **3-gradient-trees.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   importance = sb.inspect.PermutationImportance(\n      data, features, target, model, metrics, n_repeats=10, tfdf=True)\n   sb.plot.save(\n      importance.plot(\n         metric_name='accuracy',\n         annotations_alignment = 'left',\n         xmin = 0.62),\n      filename='{}-permutation-importance-accuracy.png'.format(prefix))\n\nresulting in the plot shown in Figure 6:\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/2-tensorflow-decision-forests/gradient-trees-permutation-importance-accuracy.png\n          :height: 500px\n\n          Figure 6: Permutation importance\n\nWe can see to what values the metric, in this case the classification accuracy,\ndecreases when each one of the feature variables is randomly permuted. Each\nfeature is permuted ``n_repeats`` times and the average and standard\ndeviation of the resulting metrics are calculated. The standard deviations\nare used to draw horizontal error bars on the average deteriorated metrics,\nbut can also be printed into the plot.\n\nWe can see that the gradient boosted trees classifier relies most heavily\non age, the average glucose level and the BMI, with the accuracy dropping\nby about 31%, 23% and 16%, respectively, when the corresponding values are\nscrambled.\n\nWhile the approach behind permutation importance is model-agnostic, care\nhas to be taken in interpreting the results when some of the features are\ncorrelated. In this case, information from the missing permuted feature\ncan at least partly be recovered by the classifier from the remaining\ncorrelated variable(s), leading to a less-than-expected deterioration\nof the studied metric. To overcome this limitation,\n:class:`spellbook.inspect.PermutationImportance` provides a mechanism for\ngrouping multiple features into clusters and permuting them simultaneously.\n\nFurther info:\n\n- https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n- https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html\n\n\n\n## Comparison Against Neural Networks\n\nFinally, let's compare our tree classifiers against the final neural network\nclassifier trained at the end of\n:doc:`/examples/1-binary-stroke-prediction/index` using both oversampling and\ninput normalisation and have a look at the different *Receiver Operator\nCharacteristic* (:term:`ROC`) curves, calculated and plotted with\n:class:`spellbook.train.ROCPlot`:\n\n.. margin:: from **4-roc.py**\n\n   in ``examples/2-tensorflow-decision-forests/``\n\n.. code:: python\n\n   import spellbook as sb\n\n   # load the pickled ROC curves of the different models\n   roc_network = sb.train.ROCPlot.pickle_load(\n       '../1-binary-stroke-prediction/oversampling-normalised-e2000-roc.pickle')\n   roc_forest = sb.train.ROCPlot.pickle_load('random-forest-roc.pickle')\n   roc_trees = sb.train.ROCPlot.pickle_load('gradient-trees-roc.pickle')\n   \n   # add and style the ROC curves\n   roc = sb.train.ROCPlot()\n   roc += roc_network\n   roc.curves['oversampling normalised / 2000 epochs (validation)']['line'].set_color('black')\n   roc.curves['oversampling normalised / 2000 epochs (training)']['line'].set_color('black')\n   roc += roc_trees\n   roc.curves['gradient trees (validation)']['line'].set_color('C1')\n   roc.curves['gradient trees (training)']['line'].set_color('C1')\n   roc += roc_forest\n   \n   # calculate and draw the working points with 100% true positive rate\n   WPs = []\n   WPs.append(roc.get_WP(\n       'oversampling normalised / 2000 epochs (validation)', TPR=1.0))\n   WPs.append(roc.get_WP(\n       'gradient trees (validation)', TPR=1.0))\n   WPs.append(roc.get_WP(\n       'random forest (validation)', TPR=1.0))\n   roc.draw_WP(WPs, linecolor=['black', 'C1', 'C0'])\n   \n   # save the plot\n   sb.plot.save(roc.plot(xmin=-0.2, xmax=11.0, ymin=50.0), 'roc.png')\n\nThe resulting :term:`ROC` curves with the working points at 100% *true positive\nrate* (:term:`TPR`) indicated are shown in Figure 7.\n\n.. list-table::\n   :class: spellbook-gallery-wrap\n\n   * - .. figure:: /images/examples/2-tensorflow-decision-forests/roc.png\n          :height: 450px\n\n          Figure 7: Receiver Operator Characteristic (:term:`ROC`) curves\n\nThere, we can see that both the decision forest and the gradient boosted trees\noutperform the neural network model, reaching lower *false positive rates*\n(:term:`FPR`) of 0.2% and 2.5%, respectively, while maintaining\n100% :term:`TPR`. Let's also keep in mind that this is not only without any\n:term:`hyperparameter tuning` but even just using the defaults.\nFurthermore, while it took about an hour to train the neural network classifier\non a fairly standard laptop, fitting the decision tree models was a matter\nof a few seconds.\n\nThis illustrates that decision trees tend to prefer *structured data*, i.e.\ndata showing its characteristic patterns when represented in a table with the\nfeatures in the columns and each datapoint in a row.\nWhile images, being a typical example of *unstructured data*, can also be\nrepresented in such a tabular manner, with each pixel in its own column, this\nis not a representation geared towards showing the characteristic patterns\n- which can e.g. move across the image and therefore from some columns to\nothers. Neural networks are better at identifying and learning the relevant\npatterns in such unstructured datasets.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}